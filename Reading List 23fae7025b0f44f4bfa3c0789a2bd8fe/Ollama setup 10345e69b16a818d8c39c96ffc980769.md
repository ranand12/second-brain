# Ollama setup

Column: https://www.linkedin.com/feed/update/urn:li:activity:7241338694513627136
Processed: Yes
created on: September 16, 2024 7:30 AM

𝗥𝘂𝗻𝗻𝗶𝗻𝗴 𝗟𝗟𝗠𝘀 𝗹𝗼𝗰𝗮𝗹𝗹𝘆 - 𝗮 𝘀𝗶𝗺𝗽𝗹𝗲, 𝟯-𝘀𝘁𝗲𝗽 𝘁𝘂𝘁𝗼𝗿𝗶𝗮𝗹 🏎️ I have found myself quite a few times in situations where I quickly wanted to experiment with a new LLM that was just released. And while it is easier than ever to spin up a GPU instance with one of the many cloud/service providers to get an LLM up and running, I always feel a special (and maybe irrational) joy when I get to run it locally. I have an M1 Macbook Pro with 64GB RAM and I'm able to run LLMs up to 70B (quantised) at decent speed on this machine. My tool of choice to do that is [Ollama](https://www.linkedin.com/company/ollama?trk=public_post-text), I find it dead-easy to set it up and get started, see slides below. There is also a bonus section on how to set up a ChatGPT-like web UI via [Open WebUI](https://www.linkedin.com/company/open-webui?trk=public_post-text). There are many ways to install this WebUI, check out their documentation and pick the one that is right for you.

[31](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_social-actions-reactions)   [8 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_social-actions-comments)

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment-cta)

[Refat Ametov](https://nl.linkedin.com/in/refat-ametov?trk=public_post_comment_actor-name)

Driving Business Automation & AI Integration | Co-founder of Devstark and SpreadSimple | Stoic Mindset

8m

Running LLMs locally is satisfying, especially with Ollama making it so easy. If you're setting up, focus on optimizing your resources and consider using a WebUI for a smoother experience.

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_like)   [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_reply)

[Hasan Z.](https://tr.linkedin.com/in/hasan-zamzam?trk=public_post_comment_actor-name)

Cybersecurity || Web3 || Jailbreak || AI || Human Rights

1h

Ollama is a good choice to run LLMs on your local computer as you can download and setup the UI in one place, but I noticed it's running slowly, I tried both Phi3 and LLama3 both run slowly on my CPU i5 CPU. Maybe I should give it a try on my Mac too 💡 .

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_like)   [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_reply)

[James Huckle](https://uk.linkedin.com/in/james-huckle?trk=public_post_comment_actor-name)

Chief of AI Research & Development at AutogenAI | Ex-Olympian

1h

That's my go-to setup too 🚀

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_like)   [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_reply)

[Ben Torben-Nielsen, PhD, MBA](https://ch.linkedin.com/in/ben-torben-nielsen?trk=public_post_comment_actor-name)

AI and Innovation leader | PhD in AI | IMD EMBA | Connecting people, tech and ideas to make AI work for you

1h

This is a great resource! I have a similar setup at home [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_comment-text) (ollama, open webui and some other tools). But please don't use Gemma 2B. Gemma always responds to me like it is a cheeky, presumptious teenager :-) Other small models like Llama 3.1 7B and phi3 3.8B respond in a more helpful way.

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_like)   [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_reply)

[Suraj Sharma](https://in.linkedin.com/in/creativesuraj?trk=public_post_comment_actor-name)

Founder and Principal Consultant

2h

That’s awesome! I’ve tried Ollama too, and it’s super easy to get started with. Running LLMs locally, especially on an M1 Mac, gives that extra bit of satisfaction. Great tip on the WebUI setup as well—thanks for sharing!

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_like)   [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_reply)

[Christiaan Hees](https://nl.linkedin.com/in/christiaanhees?trk=public_post_comment_actor-name)

Customer Engineer at Google

36m

Oh hey, Open WebUI looks interesting. Thanks for the tip 😀

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_like)   [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_comment_reply)

[See more comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_see-more-comments)

To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fheikohotz_ollama-setup-activity-7241338694513627136-u8CY&trk=public_post_feed-cta-banner-cta)

## More Relevant Posts

- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   1d    [86](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_what-a-week-huh-below-three-hand-picked-activity-7240970122423603200-YT4f&trk=public_post_main-feed-card_social-actions-reactions)   [5 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_what-a-week-huh-below-three-hand-picked-activity-7240970122423603200-YT4f&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_what-a-week-huh-below-three-hand-picked-activity-7240970122423603200-YT4f&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_what-a-week-huh-below-three-hand-picked-activity-7240970122423603200-YT4f&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    What a week, huh? Below three hand-picked resources that I found useful this week to catch up on hot topics in AI. They will take you only a few minutes to read through, but hopefully will leave you thinking for a while 😉 👉 𝙃𝙖𝙣𝙙𝙨-𝙤𝙣 𝙜𝙪𝙞𝙙𝙚 𝙤𝙣 𝙍𝙚𝙛𝙡𝙚𝙘𝙩𝙞𝙤𝙣 𝙏𝙪𝙣𝙞𝙣𝙜 by [Sebastian Raschka, PhD](https://www.linkedin.com/in/sebastianraschka?trk=public_post_main-feed-card-text): Sebastian points out that improving (instead of just growing) datasets to train LLMs has become an important theme lately. In his notebook he shows how to do that using GPT-4. 🔗 [https://lnkd.in/e_TDEmp5](https://lnkd.in/e_TDEmp5?trk=public_post_main-feed-card-text) 👉 𝙁𝙞𝙧𝙨𝙩 𝙞𝙢𝙥𝙧𝙚𝙨𝙨𝙞𝙤𝙣𝙨 𝙖𝙣𝙙 𝙩𝙝𝙤𝙪𝙜𝙝𝙩𝙨 𝙤𝙣 𝙤1 by [Jim Fan](https://www.linkedin.com/in/drjimfan?trk=public_post_main-feed-card-text): There are obviously many takes and thoughts on o1 out so far. I personally really like this one by Jim, it's short and sweet, but made me think a lot about the upcoming paradigm shift. One sentence that really rang true for me: 𝘗𝘳𝘰𝘥𝘶𝘤𝘵𝘪𝘰𝘯𝘪𝘻𝘪𝘯𝘨 𝘰1 𝘪𝘴 𝘮𝘶𝘤𝘩 𝘩𝘢𝘳𝘥𝘦𝘳 𝘵𝘩𝘢𝘯 𝘯𝘢𝘪𝘭𝘪𝘯𝘨 𝘵𝘩𝘦 𝘢𝘤𝘢𝘥𝘦𝘮𝘪𝘤 𝘣𝘦𝘯𝘤𝘩𝘮𝘢𝘳𝘬𝘴. 🔗 [https://lnkd.in/eHZWsPVb](https://lnkd.in/eHZWsPVb?trk=public_post_main-feed-card-text) 👉 𝙍𝙚𝙙𝙪𝙘𝙞𝙣𝙜 𝙇𝙇𝙈 𝙝𝙖𝙡𝙡𝙪𝙘𝙞𝙣𝙖𝙩𝙞𝙤𝙣𝙨 𝙪𝙨𝙞𝙣𝙜 𝙍𝙚𝙩𝙧𝙞𝙚𝙫𝙖𝙡 𝙄𝙣𝙩𝙚𝙧𝙡𝙚𝙖𝙫𝙚𝙙 𝙂𝙚𝙣𝙚𝙧𝙖𝙩𝙞𝙤𝙣 (𝙍𝙄𝙂) by [Google](https://www.linkedin.com/company/google?trk=public_post_main-feed-card-text): I was not too familiar with this technique before DataGemma was released this week. And this one also fits into the broader topic of LLMs + Reasoning: Gemma 2 is being fine-tuned to recognise when it needs to replace a generated number with more accurate information from Data Commons. Think of it as the model double-checking its work against a trusted source. 🔗 [https://lnkd.in/egnHvBWv](https://lnkd.in/egnHvBWv?trk=public_post_main-feed-card-text) 𝙇𝙚𝙩 𝙢𝙚 𝙠𝙣𝙤𝙬 𝙬𝙝𝙞𝙘𝙝 𝙤𝙣𝙚 (𝙞𝙛 𝙖𝙣𝙮) 𝙮𝙤𝙪 𝙛𝙤𝙪𝙣𝙙 𝙝𝙚𝙡𝙥𝙛𝙪𝙡 😊
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E22AQE1DcG9GLpQkg/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1726376275363?e=2147483647&v=beta&t=Kq9Ur5W4Ljh1JbAOUV6M7wWOx2BMq01jn_MvbDp8Sao)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_what-a-week-huh-below-three-hand-picked-activity-7240970122423603200-YT4f&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   2d Edited    [163](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7240613101526556673-skcp&trk=public_post_main-feed-card_social-actions-reactions)   [19 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7240613101526556673-skcp&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7240613101526556673-skcp&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7240613101526556673-skcp&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗢𝗽𝗲𝗻𝗔𝗜'𝘀 𝗼𝟭 𝗺𝗼𝗱𝗲𝗹 𝗰𝗿𝗲𝗮𝘁𝗲𝘀 𝗮𝗻 𝗲𝗻𝘁𝗶𝗿𝗲𝗹𝘆 𝗻𝗲𝘄 𝗟𝗟𝗠 𝘁𝗶𝗲𝗿 In my experience there are currently four dimensions that organisations consider when deciding which LLMs to use in production. 👉 Quality 👉 Price 👉 Speed 👉 Context window size The order of importance for each of these dimensions depends on the use case. Up until this week the model landscape was roughly divided into two tiers (wrt price/speed/quality): 1️⃣ Smaller models that are fast and inexpensive, but with slightly lower quality (GPT4o-mini, Gemini 1.5 Flash, Claude 3 Haiku, etc) 2️⃣ Premium models with top quality but not as fast and a higher price tag (think GPT4o, Gemini 1.5 Pro, Claude 3.5 Sonnet, etc) In the two-tier landscape I have observed that small models are being used for high usage scenarios where speed and cost-efficiency are crucial, such as real-time chat applications, content moderation, or large-scale data processing tasks. These models are great in situations where a quick response is more valuable than perfect accuracy. Premium models, on the other hand, are being used by organisations when for tasks requiring high precision, complex reasoning, or nuanced understanding. They're often deployed into production in specialised fields like legal analysis, advanced research, or high-stakes decision-making processes. -------------------------------------------------------------- The arrival of o1 created an entire new tier, redefining the state of the art with its impressive quality, but which also comes at a price. The introduction of this new tier raises interesting questions about the future of LLM applications: while o1's impressive quality sets a new benchmark, its higher price point and potentially increased token usage (because of the reasoning chain) may limit its practical applications in many business scenarios. 𝙒𝙝𝙖𝙩 𝙖𝙧𝙚 𝙮𝙤𝙪𝙧 𝙩𝙝𝙤𝙪𝙜𝙝𝙩𝙨 𝙤𝙣 𝙩𝙝𝙞𝙨 𝙣𝙚𝙬 𝙩𝙞𝙚𝙧? 𝙃𝙤𝙬 𝙙𝙤 𝙮𝙤𝙪 𝙨𝙚𝙚 𝙞𝙩 𝙛𝙞𝙩𝙩𝙞𝙣𝙜 𝙞𝙣𝙩𝙤 𝙮𝙤𝙪𝙧 𝙤𝙧𝙜𝙖𝙣𝙞𝙨𝙖𝙩𝙞𝙤𝙣'𝙨 𝘼𝙄 𝙨𝙩𝙧𝙖𝙩𝙚𝙜𝙮, 𝙞𝙛 𝙖𝙩 𝙖𝙡𝙡? 𝘼𝙧𝙚 𝙩𝙝𝙚𝙧𝙚 𝙨𝙥𝙚𝙘𝙞𝙛𝙞𝙘 𝙪𝙨𝙚 𝙘𝙖𝙨𝙚𝙨 𝙬𝙝𝙚𝙧𝙚 𝙮𝙤𝙪 𝙗𝙚𝙡𝙞𝙚𝙫𝙚 𝙤1'𝙨 𝙘𝙖𝙥𝙖𝙗𝙞𝙡𝙞𝙩𝙞𝙚𝙨 𝙘𝙤𝙪𝙡𝙙 𝙥𝙧𝙤𝙫𝙞𝙙𝙚 𝙨𝙞𝙜𝙣𝙞𝙛𝙞𝙘𝙖𝙣𝙩 𝙫𝙖𝙡𝙪𝙚 𝙙𝙚𝙨𝙥𝙞𝙩𝙚 𝙞𝙩𝙨 𝙝𝙞𝙜𝙝𝙚𝙧 𝙘𝙤𝙨𝙩?
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E10AQH22m_8VeSNvA/image-shrink_800/image-shrink_800/0/1726296662240?e=2147483647&v=beta&t=Aw720_YH9Kk_TFjp5WGz1U3yVzT8KSZnRbDdwJJ-nW8)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7240613101526556673-skcp&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   3d    [18](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_the-gen-z-and-gen-alpha-generations-are-apparently-activity-7240268756373901312-87s7&trk=public_post_main-feed-card_social-actions-reactions)   [9 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_the-gen-z-and-gen-alpha-generations-are-apparently-activity-7240268756373901312-87s7&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_the-gen-z-and-gen-alpha-generations-are-apparently-activity-7240268756373901312-87s7&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_the-gen-z-and-gen-alpha-generations-are-apparently-activity-7240268756373901312-87s7&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    The Gen Z and Gen Alpha generations are apparently not very intelligent. I mean, how else could we possibly explain that they have not produced a single Nobel Prize winner??? 🤔 [https://lnkd.in/eXmazpAc](https://lnkd.in/eXmazpAc?trk=public_post_main-feed-card-text)
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E22AQHKVBEbTIcwRA/feedshare-shrink_800/feedshare-shrink_800/0/1726214587993?e=2147483647&v=beta&t=Q9vlddNBisCNMicD9ACnEoyLYSz7TFihDfpHdez6zAU)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_the-gen-z-and-gen-alpha-generations-are-apparently-activity-7240268756373901312-87s7&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   3d    [29](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-activity-7240007899219963904-BnvR&trk=public_post_main-feed-card_social-actions-reactions)   [5 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-activity-7240007899219963904-BnvR&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-activity-7240007899219963904-BnvR&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-activity-7240007899219963904-BnvR&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗗𝗮𝘁𝗮 𝗖𝗼𝗺𝗺𝗼𝗻𝘀 + 𝗥𝗜𝗚 + 𝗥𝗔𝗚 = 𝗗𝗮𝘁𝗮𝗚𝗲𝗺𝗺𝗮 💪 [Google](https://www.linkedin.com/company/google?trk=public_post_main-feed-card-text) just released two DataGemma models which use real world data to tackle AI hallucinations. Both models use Data Commons, a publicly available knowledge graph containing over 240 𝙗𝙞𝙡𝙡𝙞𝙤𝙣 𝙧𝙞𝙘𝙝 𝙙𝙖𝙩𝙖 𝙥𝙤𝙞𝙣𝙩𝙨 from trusted organisations like the United Nations (UN), Center for Disease Control and Prevention (CDC) and global census bureaus. DataGemma comes in two flavours with two distinct approaches: 1️⃣ 𝙍𝙄𝙂 (𝙍𝙚𝙩𝙧𝙞𝙚𝙫𝙖𝙡-𝙄𝙣𝙩𝙚𝙧𝙡𝙚𝙖𝙫𝙚𝙙 𝙂𝙚𝙣𝙚𝙧𝙖𝙩𝙞𝙤𝙣): This model has been fine-tuned to generate natural language queries for Data Commons alongside its regular text output, enabling real-time fact-checking of statistical claims by retrieving verified data. An example for a RIG query and response would be: 𝘜𝘴𝘦𝘳: 𝘞𝘩𝘢𝘵'𝘴 𝘵𝘩𝘦 𝘢𝘷𝘦𝘳𝘢𝘨𝘦 𝘴𝘪𝘻𝘦 𝘰𝘧 𝘢 𝘜𝘚 𝘩𝘰𝘶𝘴𝘦𝘩𝘰𝘭𝘥? 𝘋𝘢𝘵𝘢𝘎𝘦𝘮𝘮𝘢: 𝘛𝘩𝘦 𝘢𝘷𝘦𝘳𝘢𝘨𝘦 𝘴𝘪𝘻𝘦 𝘰𝘧 𝘢 𝘜𝘚 𝘩𝘰𝘶𝘴𝘦𝘩𝘰𝘭𝘥 𝘪𝘴 [𝘋𝘊("𝘸𝘩𝘢𝘵 𝘸𝘢𝘴 𝘵𝘩𝘦 𝘢𝘷𝘦𝘳𝘢𝘨𝘦 𝘩𝘰𝘶𝘴𝘦𝘩𝘰𝘭𝘥 𝘴𝘪𝘻𝘦 𝘪𝘯 𝘵𝘩𝘦 𝘜𝘯𝘪𝘵𝘦𝘥 𝘚𝘵𝘢𝘵𝘦𝘴 𝘪𝘯 2021?") --> "2.53"] 𝘱𝘦𝘰𝘱𝘭𝘦. As we can see, the RIG model produces a response that includes both the LLM-generated text and the Data Commons queries embedded within it. And then there is a post-processing step that resolves the Data Commons queries and replaces them with actual data, before sending the final response to the user. 2️⃣ 𝙍𝘼𝙂 (𝙍𝙚𝙩𝙧𝙞𝙚𝙫𝙖𝙡-𝘼𝙪𝙜𝙢𝙚𝙣𝙩𝙚𝙙 𝙂𝙚𝙣𝙚𝙧𝙖𝙩𝙞𝙤𝙣): This model's role is limited to generating relevant questions for Data Commons based on the user's query. The response is then passed on to Gemini 1.5 Pro, leveraging its long context window to produce the final response. So this model is only a part of a larger LLM application. 𝗥̲𝗲̲𝘀̲𝘂̲𝗹̲𝘁̲𝘀̲ 𝙍𝙄𝙂: 👉 Improved factual accuracy from 5-17% to about 58% 👉 User preference: 62% (7B model) to 76% (27B model) over baseline 𝙍𝘼𝙂: 👉 Statistical claims accuracy: 98.6-98.9% 👉 Coverage: 24-29% of queries had statistical responses 👉 User preference: 92-100% when Data Commons stats were used Both approaches showed significant improvements over baseline models in terms of factual accuracy and user preference, with RAG generally performing better when data was available. Blog post, technical paper, and model links below in the comments 🤗
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E22AQGJpeZUEE52Yg/feedshare-shrink_800/feedshare-shrink_800/0/1726152395191?e=2147483647&v=beta&t=nvc2qkAbCszZ1LHhL_9H34YXFmHPk2884k6FW2mvHDg)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-activity-7240007899219963904-BnvR&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   4d    [18](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F-%253F%253F-%253F-activity-7239887462699868161-y917&trk=public_post_main-feed-card_social-actions-reactions)   [4 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F-%253F%253F-%253F-activity-7239887462699868161-y917&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F-%253F%253F-%253F-activity-7239887462699868161-y917&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F-%253F%253F-%253F-activity-7239887462699868161-y917&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗡𝗼𝘁𝗲𝗯𝗼𝗼𝗸𝗟𝗠 𝗹𝗲𝗮𝗿𝗻𝘀 𝘁𝗼 𝘀𝗽𝗲𝗮𝗸 🎤 Just a few days ago I posted about [Google](https://www.linkedin.com/company/google?trk=public_post_main-feed-card-text)'s Illuminate that will turn PDFs (for example research papers) into podcasts. Not NotbookLM has followed suit and introduced Audio Overview. With this new feature, users can now listen to AI-generated discussions about their sources. These discussions summarise the material, make connections between topics, and can be downloaded for on-the-go listening. I personally process and retain information more effectively when it's presented in spoken form. So while the dialogue is not perfect and not a replacement for real podcasts (for me anyway), I find it a great learning tool 🤗 The features is now generally available, so go and try it out yourself.
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E22AQEtFT6vVO5pOw/feedshare-shrink_800/feedshare-shrink_800/0/1726123680156?e=2147483647&v=beta&t=njxk7S2tU6ZgaIQVT2xSf75bVTS31gdaYDaJGqNlk9A)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F-%253F%253F-%253F-activity-7239887462699868161-y917&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   5d    [19](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-use-control-generated-activity-7239508597758439424-JUCG&trk=public_post_main-feed-card_social-actions-reactions)   [7 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-use-control-generated-activity-7239508597758439424-JUCG&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-use-control-generated-activity-7239508597758439424-JUCG&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-use-control-generated-activity-7239508597758439424-JUCG&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗣𝗿𝗼 𝗟𝗟𝗠 𝗧𝗶𝗽 Use control-generated output — because life with LLMs is already hard enough 😝 ⚠️ 𝙏𝙧𝙞𝙜𝙜𝙚𝙧 𝙬𝙖𝙧𝙣𝙞𝙣𝙜: 𝙎𝙤𝙢𝙚 𝙤𝙛 𝙩𝙝𝙚 𝙧𝙚𝙨𝙥𝙤𝙣𝙨𝙚𝙨 𝙞𝙣 𝙩𝙝𝙚 𝙞𝙢𝙖𝙜𝙚 𝙗𝙚𝙡𝙤𝙬 𝙖𝙧𝙚 𝙙𝙚𝙚𝙢𝙚𝙙 𝙝𝙞𝙜𝙝𝙡𝙮 𝙘𝙤𝙣𝙩𝙧𝙤𝙫𝙚𝙧𝙨𝙞𝙖𝙡 𝙖𝙣𝙙 𝙢𝙞𝙜𝙝𝙩 𝙘𝙖𝙪𝙨𝙚 𝙮𝙤𝙪𝙧 𝙗𝙡𝙤𝙤𝙙 𝙥𝙧𝙚𝙨𝙨𝙪𝙧𝙚 𝙩𝙤 𝙧𝙞𝙨𝙚 😜 ⚠️
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E22AQHtjC7ko0rqHg/feedshare-shrink_800/feedshare-shrink_800/0/1726033352503?e=2147483647&v=beta&t=An9B6y5F4Fl-bc2rGz08dwO09tY8CvC03QncE6cbPU8)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F-%253F%253F%253F-%253F%253F%253F-use-control-generated-activity-7239508597758439424-JUCG&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   6d    [43](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7239153435013500928-G406&trk=public_post_main-feed-card_social-actions-reactions)   [4 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7239153435013500928-G406&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7239153435013500928-G406&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7239153435013500928-G406&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗧𝗿𝗮𝗻𝘀𝗳𝗼𝗿𝗺 𝘆𝗼𝘂𝗿 𝗰𝗼𝗻𝘁𝗲𝗻𝘁 📕 𝗶𝗻𝘁𝗼 𝗮 𝗽𝗼𝗱𝗰𝗮𝘀𝘁 🎤 Last night I tried [Google](https://www.linkedin.com/company/google?trk=public_post_main-feed-card-text)'s 𝙄𝙡𝙡𝙪𝙢𝙞𝙣𝙖𝙩𝙚 for the first time, and I think my jaw dropped on the floor for 7 minutes straight 🤯 𝙄𝙡𝙡𝙪𝙢𝙞𝙣𝙖𝙩𝙚 lets you convert research papers (and probably other PDFs) into podcasts - you just paste in the URL of a PDF, press a button, and voilà: your podcast is ready. For me as a regular podcast listener this is huge. Admittedly, the dialogue is a bit clunky - I had the model create a podcast about the AI Scientist paper from a few weeks ago and I believe the "guest" on the podcast answered every single question with "The AI Scientist framework ..." 😅 But, as always, this is the worst this technology will ever be going forward, and that is exciting. Especially when we get more influence over the how the podcast is created (length/tone/details/etc) and maybe even interact with it ("A listener has a question ...") 🤗 𝙄𝙡𝙡𝙪𝙢𝙞𝙣𝙖𝙩𝙚 has been released for public preview, link in the comments below.
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F%253F-%253F%253F%253F%253F%253F%253F%253F-activity-7239153435013500928-G406&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   1w Edited    [70](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F%253F%253F%253F-activity-7238796815486111746-d6K-&trk=public_post_main-feed-card_social-actions-reactions)   [11 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F%253F%253F%253F-activity-7238796815486111746-d6K-&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F%253F%253F%253F-activity-7238796815486111746-d6K-&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F%253F%253F%253F-activity-7238796815486111746-d6K-&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗥𝗲𝗳𝗹𝗲𝗰𝘁𝗶𝗼𝗻 𝟳𝟬𝗕 𝗨𝗽𝗱𝗮𝘁𝗲 👉 Over the weekend and new model called Reflection 70B made a splash in the AI community, claiming impressive results on several benchmarks and beating GPT4o and Claude 3.5. 👉 Independent reviewers like [Artificial Analysis](https://www.linkedin.com/company/artificial-analysis?trk=public_post_main-feed-card-text) were not able to reproduce the results 👉 The creators of the model identified an issue with the weights of the model that they published on [Hugging Face](https://www.linkedin.com/company/huggingface?trk=public_post_main-feed-card-text) 👉 On Sunday, the creators re-trained and re-tested the model and they think they fixed the issue 👉 They made the new version available on OpenRouter (i.e. behind an API with no access to the weights) 👉 When testing this new version, users hints that it was a wrapper around Claude Sonnet 3.5: [https://lnkd.in/eadNf2R7](https://lnkd.in/eadNf2R7?trk=public_post_main-feed-card-text) 👉 [Artificial Analysis](https://www.linkedin.com/company/artificial-analysis?trk=public_post_main-feed-card-text) was given access to a private API for re-evaluation and was able to confirm the new results 👉 After that, new weights of the model were published on [https://lnkd.in/ejC2ntPi](https://lnkd.in/ejC2ntPi?trk=public_post_main-feed-card-text) 👉 [Artificial Analysis](https://www.linkedin.com/company/artificial-analysis?trk=public_post_main-feed-card-text) was NOT able to reproduce the claimed resulst with these new model weights and has questions: [https://lnkd.in/eH9jPvQp](https://lnkd.in/eH9jPvQp?trk=public_post_main-feed-card-text) --------------------------------------- Something clearly has gone wrong here, but here is what I would say: (1) I still believe that the technique of reflection in an LLM application can improve performance. (2) If I had been the one who created this new model and would have seen the crazy buzz and interest around it there would have been a 100% chance I would have been overwhelmed as well and would have made some unforced errors. Let's wait and see - and let's remember to be kind! The good thing is the technique is not new and well known (finetuning with synthetic dataset) and also not too expensive, so if push comes to shove others can try to build a similar model in their own time without any distracting buzz around it.
    
    - 
        
        [](https://media.licdn.com/dms/image/v2/D4E22AQGJMbHavQcAew/feedshare-shrink_800/feedshare-shrink_800/0/1725863649923?e=2147483647&v=beta&t=LMIN04DMEsPbUPL9nK2yiWypVi1pOpR3YsibMYzljO4)
        
        No alternative text description for this image
        
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F%253F-%253F%253F%253F%253F%253F%253F-activity-7238796815486111746-d6K-&trk=public_post_main-feed-card_feed-cta-banner-cta)
    
- [Heiko Hotz](https://uk.linkedin.com/in/heikohotz/en?trk=public_post_main-feed-card_feed-actor-name)   1w Edited   [48](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-activity-7238452200165838848-Kw_f&trk=public_post_main-feed-card_social-actions-reactions)   [16 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-activity-7238452200165838848-Kw_f&trk=public_post_main-feed-card_social-actions-comments)   [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-activity-7238452200165838848-Kw_f&trk=public_post_main-feed-card_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-activity-7238452200165838848-Kw_f&trk=public_post_main-feed-card_comment-cta)
    
    Generative AI Global Blackbelt @ Google ◆ Founder of NLP London
    
    𝗥𝗲𝗳𝗹𝗲𝗰𝘁𝗶𝗻𝗴 𝗼𝗻 𝙍𝙚𝙛𝙡𝙚𝙘𝙩𝙞𝙤𝙣 70𝘽 !!! 𝗜𝗠𝗣𝗢𝗥𝗧𝗔𝗡𝗧 𝗨𝗣𝗗𝗔𝗧𝗘 👉 (𝟴 𝗦𝗲𝗽, 𝟭𝗽𝗺 𝗕𝗦𝗧): 𝗔𝗽𝗽𝗮𝗿𝗲𝗻𝘁𝗹𝘆 𝘁𝗵𝗲𝗿𝗲 𝘄𝗮𝘀 𝗮𝗻 𝗶𝘀𝘀𝘂𝗲 𝘄𝗶𝘁𝗵 𝘁𝗵𝗲 𝗺𝗼𝗱𝗲𝗹 𝘄𝗵𝗲𝗻 𝘁𝗵𝗲 𝗮𝘂𝘁𝗵𝗼𝗿𝘀 𝗳𝗶𝗿𝘀𝘁 𝘂𝗽𝗹𝗼𝗮𝗱𝗲𝗱 𝗶𝘁. They are working on it, you can follow Matt on Twitter for updates (e.g. [https://lnkd.in/e2swBkuB](https://lnkd.in/e2swBkuB?trk=public_post_main-feed-card-text)) 👉 (𝟵 𝗦𝗲𝗽, 𝟳𝗮𝗺 𝗕𝗦𝗧): 𝗧𝗵𝗲 𝗮𝘂𝘁𝗵𝗼𝗿𝘀 𝘂𝗽𝗹𝗼𝗮𝗱𝗲𝗱 𝗻𝗲𝘄 𝘄𝗲𝗶𝗴𝗵𝘁𝘀 𝗮𝗻𝗱 𝘁𝗵𝗲𝘆 𝗯𝗲𝗹𝗶𝗲𝘃𝗲 𝘁𝗵𝗲 𝗶𝘀𝘀𝘂𝗲 𝗶𝘀 𝗳𝗶𝘅𝗲𝗱. [Artificial Analysis](https://www.linkedin.com/company/artificial-analysis?trk=public_post_main-feed-card-text) cannot confirm and has questions: [https://lnkd.in/eH9jPvQp](https://lnkd.in/eH9jPvQp?trk=public_post_main-feed-card-text) !!! A few months ago I was discussing with [James Huckle](https://uk.linkedin.com/in/james-huckle?trk=public_post_main-feed-card-text) on how to improve the performance of LLMs where they make seemingly “easy” mistakes ("easy" from a human point of view). I suggested a mechanism where the model can 𝗿𝗲𝗳𝗹𝗲𝗰𝘁 on its immediate response in order to identify any mistakes it might have made and 𝗴𝗶𝘃𝗲 𝘁𝗵𝗲 𝗺𝗼𝗱𝗲𝗹 𝗮 𝗰𝗵𝗮𝗻𝗰𝗲 𝘁𝗼 𝗿𝗲𝗰𝗼𝘃𝗲𝗿. [Matt Shumer](https://www.linkedin.com/in/mattshumer?trk=public_post_main-feed-card-text) & [Sahil Chaudhary](https://nl.linkedin.com/in/sahil-chaudhary-981428132?trk=public_post_main-feed-card-text) had a similar idea and simplified it even further: They fine-tuned a Llama-3.1 70B model to have this 𝗿𝗲𝗳𝗹𝗲𝗰𝘁𝗶𝗼𝗻 𝗺𝗼𝗱𝗲 𝗯𝘂𝗶𝗹𝘁 𝗶𝗻. So, rather than having to make two LLM calls this model does it all in one. This model is called 𝙍𝙚𝙛𝙡𝙚𝙘𝙩𝙞𝙤𝙣 70𝘽 and it seems a 405B version is coming soon. And it seems that the idea of making LLMs reflect is rather successful - Reflection 70B is crushing several SOTA models on a range of benchmarks. Now, it is worth noting that this is not a great model to “just have a chat with”. In my experience it will always print its reflections before responding, so a simple “Hello” exchange can be quite “interesting” 😉 𝘉𝘺 𝘵𝘩𝘦 𝘸𝘢𝘺, 𝘵𝘩𝘦 𝘮𝘰𝘥𝘦𝘭 (𝘲𝘶𝘢𝘯𝘵𝘪𝘻𝘦𝘥 𝘷𝘦𝘳𝘴𝘪𝘰𝘯) 𝘳𝘶𝘯𝘴 𝘢𝘵 𝘢 𝘥𝘦𝘤𝘦𝘯𝘵 𝘴𝘱𝘦𝘦𝘥 𝘭𝘰𝘤𝘢𝘭𝘭𝘺 𝘰𝘯 𝘢 𝘔𝘢𝘤𝘉𝘰𝘰𝘬 𝘗𝘳𝘰 𝘔1 (64𝘎𝘉 𝘙𝘈𝘔). 𝘐𝘧 𝘺𝘰𝘶 𝘩𝘢𝘷𝘦 𝘢 𝘴𝘪𝘮𝘪𝘭𝘢𝘳𝘭𝘺 𝘴𝘱𝘦𝘤’𝘥 𝘮𝘢𝘤𝘩𝘪𝘯𝘦 𝘢𝘯𝘥 𝘸𝘰𝘶𝘭𝘥 𝘭𝘪𝘬𝘦 𝘵𝘰 𝘬𝘯𝘰𝘸 𝘮𝘰𝘳𝘦 𝘩𝘰𝘸 𝘵𝘰 𝘴𝘦𝘵 𝘪𝘵 𝘶𝘱, 𝘭𝘦𝘵 𝘮𝘦 𝘬𝘯𝘰𝘸 - 𝘐 𝘮𝘪𝘨𝘩𝘵 𝘮𝘢𝘬𝘦 𝘢 𝘲𝘶𝘪𝘤𝘬 𝘵𝘶𝘵𝘰𝘳𝘪𝘢𝘭 𝘰𝘯 𝘵𝘩𝘢𝘵.
    
    To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fheikohotz_%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-%253F%253F-%253F%253F%253F%253F%253F%253F%253F%253F%253F%253F-activity-7238452200165838848-Kw_f&trk=public_post_main-feed-card_feed-cta-banner-cta)